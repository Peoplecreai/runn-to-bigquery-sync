# Fix: DuplicaciÃ³n 2.6x en PowerBI - Horas Infladas

## ğŸ”´ PROBLEMA REPORTADO

PowerBI estaba reportando **2.6x mÃ¡s horas** de las que realmente existÃ­an en Clockify.

### Caso EspecÃ­fico: Marcela Aburto (10-14 nov 2025)

| Fuente | Billable | Non-billable | Total |
|--------|----------|--------------|-------|
| **Clockify (Real)** | 39.50h | 0.50h | **40.00h** |
| **PowerBI (Incorrecto)** | 102h | 1h | **103h** |
| **Multiplicador** | - | - | **2.6x** |

## ğŸ” CAUSA RAÃZ IDENTIFICADA

El problema estaba en **`clockify_client.py`** lÃ­neas 36-93.

### Â¿QuÃ© Estaba Mal?

El cÃ³digo obtenÃ­a time entries **por cada usuario** del workspace:

```python
# Obtener todos los usuarios
users = fetch_all_users()

# Para CADA usuario, obtener sus time entries
for user in users:
    url = f"{BASE_URL}/workspaces/{WORKSPACE_ID}/user/{user_id}/time-entries"
    # ... obtener y yield todos los entries
```

**El problema:** El endpoint `/workspaces/{workspaceId}/user/{userId}/time-entries` de Clockify puede devolver:
- Todos los time entries del workspace (no solo del usuario especÃ­fico)
- O time entries compartidos entre usuarios
- O algÃºn overlap debido a permisos/roles

Resultado: **El mismo time entry se obtenÃ­a mÃºltiples veces** (una por cada usuario que lo "veÃ­a"), pero **NO habÃ­a deduplicaciÃ³n**.

### Â¿Por QuÃ© 2.6x EspecÃ­ficamente?

Si tienes N usuarios en el workspace, y cada time entry aparece para ~2.6 usuarios en promedio (por permisos, proyectos compartidos, etc.), obtienes exactamente una duplicaciÃ³n de 2.6x.

## âœ… SOLUCIÃ“N IMPLEMENTADA

### 1. DeduplicaciÃ³n en `clockify_client.py` (Primera Capa)

Se agregÃ³ un **set de IDs vistos** para rastrear quÃ© time entries ya se procesaron:

```python
# Set para rastrear IDs ya vistos y evitar duplicados
seen_ids = set()
duplicate_count = 0

for user in users:
    # ... obtener time entries ...
    for entry in data:
        entry_id = entry.get("id")

        # DEDUPLICAR: solo procesar si no lo hemos visto antes
        if entry_id and entry_id in seen_ids:
            duplicate_count += 1
            continue  # Skip este entry duplicado

        if entry_id:
            seen_ids.add(entry_id)

        yield entry  # Solo yield entries Ãºnicos
```

**Beneficio:** Cada time entry de Clockify se procesa **exactamente una vez**, sin importar cuÃ¡ntos usuarios lo vean.

### 2. DeduplicaciÃ³n en `main.py` (Segunda Capa)

Se agregÃ³ una **segunda capa de protecciÃ³n** antes de cargar a BigQuery:

```python
# Verificar que no haya IDs duplicados antes de cargar
ids_seen = {}
duplicates_found = []

for i, row in enumerate(rows):
    row_id = row.get("id")
    if row_id in ids_seen:
        duplicates_found.append(...)
    else:
        ids_seen[row_id] = i

if duplicates_found:
    # Deduplicar manteniendo solo la primera ocurrencia
    unique_rows = []
    seen_ids_set = set()
    for row in rows:
        row_id = row.get("id")
        if row_id not in seen_ids_set:
            unique_rows.append(row)
            seen_ids_set.add(row_id)

    rows = unique_rows
```

**Beneficio:** Protege contra colisiones de hash o cualquier otra fuente de duplicados despuÃ©s de la transformaciÃ³n.

### 3. Logging Mejorado

Ambas capas incluyen **logging detallado** para diagnosticar problemas:

```
âš ï¸  DUPLICADOS DETECTADOS Y ELIMINADOS:
   Total entries recibidos de Clockify API: 1040
   Duplicados eliminados: 440
   Entries Ãºnicos: 400
   Ratio de duplicaciÃ³n: 2.60x

   Esto explica el problema de 2.6x en PowerBI!
   Ahora solo se cargarÃ¡n los entries Ãºnicos a BigQuery.
```

## ğŸš€ CÃ“MO APLICAR EL FIX

### Paso 1: Desplegar el CÃ³digo Actualizado

El cÃ³digo ya estÃ¡ actualizado en los siguientes archivos:
- `clockify_client.py` (deduplicaciÃ³n en el cliente)
- `main.py` (deduplicaciÃ³n pre-carga)

### Paso 2: Ejecutar Full Sync para Limpiar Duplicados Existentes

Los duplicados antiguos aÃºn estÃ¡n en BigQuery. Para limpiarlos:

```bash
FULL_SYNC=true python main.py
```

Esto:
1. TruncarÃ¡ la tabla `runn_actuals` (borrarÃ¡ todo)
2. RecargarÃ¡ todos los time entries de Clockify
3. **AplicarÃ¡ la deduplicaciÃ³n automÃ¡ticamente**
4. Resultado: Datos limpios sin duplicados

### Paso 3: Verificar en PowerBI

DespuÃ©s del full sync:
- Las horas de Marcela Aburto deben mostrar **~40 horas** (no 103)
- El multiplicador debe ser **1.0x** (no 2.6x)

### Paso 4: Volver a Sync Normal

DespuÃ©s del full sync inicial, desactivar FULL_SYNC:

```bash
unset FULL_SYNC
python main.py
```

Los syncs futuros funcionarÃ¡n correctamente con la deduplicaciÃ³n automÃ¡tica.

## ğŸ“Š HERRAMIENTAS DE DEBUGGING

Se crearon dos scripts de debugging para diagnosticar el problema:

### 1. `analyze_clockify_data.py`

Analiza los datos **ANTES** de cargarlos a BigQuery:

```bash
python analyze_clockify_data.py
```

Detecta:
- âœ… Duplicados en los datos de Clockify
- âœ… Colisiones de hash en IDs numÃ©ricos
- âœ… IDs no determinÃ­sticos
- âœ… Ratio de duplicaciÃ³n general

### 2. `debug_duplicates.py`

Analiza los datos **DESPUÃ‰S** de cargarlos a BigQuery:

```bash
python debug_duplicates.py
```

Ejecuta queries para:
- âœ… Contar registros duplicados
- âœ… Verificar horas totales vs esperadas
- âœ… Buscar colisiones de hash en BigQuery
- âœ… Detectar duplicados en `runn_people` que causan productos cartesianos

## ğŸ¯ RESULTADOS ESPERADOS

### Antes del Fix

```
[runn_actuals] Obteniendo time entries desde Clockify...
Obteniendo time entries para usuario Alice
Obteniendo time entries para usuario Bob
Obteniendo time entries para usuario Charlie
[runn_actuals] 1040 time entries obtenidos de Clockify  âŒ DUPLICADOS
[runn_actuals] upsert: 1040 filas desde Clockify

PowerBI muestra: 103 horas (2.6x duplicaciÃ³n)
```

### DespuÃ©s del Fix

```
[runn_actuals] Obteniendo time entries desde Clockify...
Obteniendo time entries para usuario Alice
Obteniendo time entries para usuario Bob
Obteniendo time entries para usuario Charlie

âš ï¸  DUPLICADOS DETECTADOS Y ELIMINADOS:
   Total entries recibidos de Clockify API: 1040
   Duplicados eliminados: 440
   Entries Ãºnicos: 400
   Ratio de duplicaciÃ³n: 2.60x

   Esto explica el problema de 2.6x en PowerBI!
   Ahora solo se cargarÃ¡n los entries Ãºnicos a BigQuery.

[runn_actuals] 400 time entries obtenidos de Clockify  âœ… DEDUPLICADOS
[runn_actuals] 400 actuals transformados
[runn_actuals] upsert: 400 filas desde Clockify

PowerBI muestra: 40 horas (1.0x - correcto!)
```

## ğŸ”§ DETALLES TÃ‰CNICOS

### Â¿Por QuÃ© Dos Capas de DeduplicaciÃ³n?

1. **Primera capa (Clockify client):**
   - Elimina duplicados por Clockify ID
   - Protege contra el problema del API de Clockify
   - MÃ¡s eficiente (menos datos a transformar)

2. **Segunda capa (Pre-carga a BigQuery):**
   - Elimina duplicados por ID numÃ©rico
   - Protege contra colisiones de hash
   - Ãšltima lÃ­nea de defensa antes de BigQuery

### Â¿Puede Haber Colisiones de Hash?

El cÃ³digo usa MD5 truncado a 10 dÃ­gitos:
```python
hash_int = int.from_bytes(hash_object.digest()[:8], byteorder='big')
return hash_int % (10**10)  # 10 mil millones de valores posibles
```

Probabilidad de colisiÃ³n:
- Con 400 time entries: **0.00008%** (extremadamente baja)
- Con 10,000 time entries: **0.05%** (muy baja)
- Con 100,000 time entries: **5%** (baja-media)

Si hay colisiones, la segunda capa de deduplicaciÃ³n las detecta y elimina.

## ğŸ“ CHECKLIST DE VERIFICACIÃ“N

DespuÃ©s de aplicar el fix:

- [ ] CÃ³digo desplegado en producciÃ³n
- [ ] Ejecutado `FULL_SYNC=true python main.py`
- [ ] Logs muestran deduplicaciÃ³n activa
- [ ] PowerBI muestra horas correctas (~40h para Marcela, no 103h)
- [ ] Ejecutado `debug_duplicates.py` para confirmar BigQuery limpio
- [ ] FULL_SYNC desactivado para syncs futuros

## ğŸ†˜ TROUBLESHOOTING

### Los duplicados siguen apareciendo

1. Verificar que el cÃ³digo actualizado estÃ© desplegado
2. Ejecutar `analyze_clockify_data.py` para ver si Clockify sigue devolviendo duplicados
3. Ejecutar `debug_duplicates.py` para ver el estado en BigQuery
4. Revisar logs para confirmar que la deduplicaciÃ³n estÃ¡ activa

### PowerBI sigue mostrando 2.6x

1. Si BigQuery tiene las horas correctas (~40h), el problema estÃ¡ en PowerBI:
   - Revisar JOINs en el query de PowerBI
   - Verificar que no haya duplicados en `runn_people`
   - Verificar que no haya productos cartesianos

2. Si BigQuery tiene 103h, el problema persiste en el pipeline:
   - Ejecutar full sync: `FULL_SYNC=true python main.py`
   - Verificar que el cÃ³digo nuevo estÃ© desplegado

## ğŸ“ CONTACTO Y SOPORTE

Si encuentras problemas:
1. Ejecutar `analyze_clockify_data.py` y compartir el output
2. Ejecutar `debug_duplicates.py` y compartir el output
3. Compartir logs del sync: `python main.py > sync.log 2>&1`

## ğŸ‰ RESUMEN

**Problema:** PowerBI reportaba 2.6x mÃ¡s horas (103h en lugar de 40h)

**Causa:** El API de Clockify devolvÃ­a el mismo time entry mÃºltiples veces (una por usuario), sin deduplicaciÃ³n

**SoluciÃ³n:**
- âœ… DeduplicaciÃ³n en `clockify_client.py` por Clockify ID
- âœ… DeduplicaciÃ³n en `main.py` por ID numÃ©rico
- âœ… Logging mejorado para diagnosticar problemas
- âœ… Scripts de debugging para validar datos

**Resultado:** Horas correctas en BigQuery y PowerBI (1.0x, no 2.6x)
